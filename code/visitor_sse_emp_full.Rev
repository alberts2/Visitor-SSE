# Phylogenetic visitor-SIR/SSE model

start_time = time("seconds")

if (!exists("update_recovery_rate")) update_recovery_rate = false
if (!exists("seed")) seed = 5
if (!exists("job_dir")) job_dir = "emp"

if (!exists("fix_R0"))     fix_R0       = false
if (!exists("fix_delta"))  fix_delta    = false
if (!exists("fix_vd"))     fix_vd       = false
if (!exists("fix_vr"))     fix_vr       = false


#tensorphylo_fp = "/mnt/c/Users/ammon_work/Desktop/phylogenetics_software/tensorphylo/build/installer/lib"
#tensorphylo_fp = "/home/athompson/software/tensorphylo/build/installer/lib"
# tensorphylo_fp = "/Users/mlandis/.local/lib/tensorphylo"
#tensorphylo_fp = "/home/mlandis/.local/lib/tensorphylo"
#tensorphylo_fp = "/Users/albertsoewongsono/Software/tensorphylo/build/installer/lib"

#loadPlugin("TensorPhylo", tensorphylo_fp)
#loadPlugin("TensorPhylo", "/tensorphylo/build/installer/lib")
loadPlugin("TensorPhylo", "/software/tensorphylo/build/installer/lib")


## Analysis settings
print_debug = false
num_gen = 7500
mv_weight = 5
print_gen = 1
anc_thin = 50
f_burn = 0.1
thin = 10
symmetric=true
move_schedule = v("random","single")[1]

## Model settings
vd_model = 4 # non-equal rates between pair of home-away
vr_model = 4 # non-equal rates between pair of home-away

## Filesystem
data_dir = "data/" + job_dir + "/"
out_dir  = "output/logs/full/"
phy_fn   = data_dir + "nadeau_full.location_tree.tre"
data_fn  = data_dir + "full.dat.ambig.nex"
# label_fn = base_fn + ".labels.csv"
out_fn   = out_dir + "out._" + "full" + ".seed_" + seed

## Read input
print(phy_fn)
tree    = readTrees(phy_fn)[1]
taxa    = tree.taxa()
num_taxa = taxa.size()
data    = readDiscreteCharacterData(data_fn)

# build compound state space
num_states = data.getStateDescriptions().size()
num_loc = round(sqrt(num_states))
home_loc = 1:num_loc
away_loc = 1:num_loc
idx = 1
for (i in home_loc) {
    for (j in away_loc) {
        joint_loc_inv[i][j] = idx
        joint_loc[idx++] = [ i, j ]
    }
}


## Set parameters

####################
# MODEL PARAMETERS #
####################

age <- tree.rootAge() + tree.branchLength(tree.nnodes())

# host population sizes
# NOTE: example numbers
S_0[1] = 57000000							# 1: Hubei 
S_0[2] = 68000000							# 2: France 
S_0[3] = 85000000							# 3: Germany 
S_0[4] = 60000000							# 4: Italy
#S_0[5] = 745000000 - (S_0[2]+S_0[3]+S_0[4])     # 5: Other European nations
S_0[5] = 245290000     # 5: Other European nations (changed to match the real data for those 16 non-focal countries)

# gamma, recovery rate
# expected waiting time to recover, 10 days
gamma <- rep(1.0/10, num_states)

# delta, sampling proportion (from Nadeau et al.)
delta_prop[1] ~ dnUniform(0,0.15)     # 1: Hubei
delta_prop[2] ~ dnUniform(0,0.093)    # 2: France
delta_prop[3] ~ dnUniform(0,0.10)     # 3: Germany
delta_prop[4] ~ dnUniform(0,0.005)    # 4: Italy
delta_prop[5] ~ dnUniform(0,0.057)    # 5: Other European

# assign sampling rate for current location j (above) to home-curr location i (below)
# \delta_i = s_i * \gamma_i / (1 - s_i), s_i = sampling proportion

for (i in 1:num_states) {
    j = joint_loc[i][2] 
    delta[i] :=  delta_prop[j]*gamma[j]/abs(1.0 - delta_prop[j])
}

# R0, reproductive number 
for (i in 1:num_loc) {
    R_0_param[i] ~ dnLognormal(0.8, 0.5^0.5)
}
for (i in 1:num_states) {
    j = joint_loc[i][2] 
    R_0[i] := R_0_param[j]
}
#R_0 := rep(R_0_param, num_states)
lambda := (delta + gamma) * R_0 

# mass sampling event parameters
rho <- 1e-6 # roughly 1 million cases
# rho <- 1e-4 # roughly 10000 cases
# possible source for more precise estimates of prevalence per region: https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data
# possibly use # deaths divided by death-probability to infer # cases

### Matrix of depart rates
#           Hubei France Germany Italy OtherEU
# Hubei
# France
# Germany
# Italy
# OtherEU
# vd(row -> column): depart rate from row to column 
md_matrix = readDataDelimitedFile("data/depart_rates.csv",TRUE,",",TRUE)
### Matrix of return rates
#           Hubei France Germany Italy OtherEU
# Hubei
# France
# Germany
# Italy
# OtherEU
# vr(row <- column): depart rate to row from column
mr_matrix = readDataDelimitedFile("data/return_rates.csv",TRUE,",",TRUE)
### standard deviation 
# assign larger sd if it involves otherEU and Hubei
sd_vd = [0.8,0.1,0.1,0.1,0.8]
sd_vr = sd_vd

# Depart model
# assume matrix D_ij for departing from home-location i into away-location j
# M1: all-equal: all depart rates equal
# M2: row-equal: all depart rates from home-location i are equal
# M3: col-equal: all depart rates into away-location j are equal
# M4: none-equal: all depart rates differ

# prior on log-rate
# exp(-8) = 0.0003354626
# exp(-5) = 0.006737947
# vd_base_dist = dnLognormal(0,1^0.5)    # units of years

# Need to back-calculate the variance for the new timescale
# > (exp(1^2) - 1) * exp(2*0 + 1^2)
# [1] 4.670774 1/year^2
#vd_mu = 0       # mu parameter of the distribution in year (from Nadeau's)
#vd_sd = 1^0.5   # sigma parameter of the distribution in year (from Nadeau's)   
#variance_nadeau = ((exp(vd_sd^2) - 1) * exp(2*vd_mu + vd_sd^2))*365^2 # variance of the distribution (from Nadeau's) in days^2

#sqr_root = (1+4*variance_nadeau/365^2)^0.5
#vd_base_dist = dnLognormal(ln(1/365), (ln((1+sqr_root)/2))^0.5) # # median depart of 365 days, 95%HPD ~ 2 months to 20 years  

# vd_base_dist = dnLognormal(ln(1/100),0.5) # median depart of 100 days, 95%HPD [43,386] days

for (i in 1:num_loc) {
    for (j in 1:num_loc) { 
        vd_rate[i][j] <- abs(0)
        vd_base_rate[i][j] <- abs(0)
        if (i != j){
            vd_base_rate[i][j] ~ dnLognormal(mean = ln(md_matrix[i][j])-0.5*sd_vd[j]^2,sd = sd_vd[j])
            # vd_base_rate[i][j].setValue(100)
            vd_rate[i][j] := ln(vd_base_rate[i][j])
        }
    }
}

# i = 1
# j = 2
# for (k in 1:1000){
#     y[k] = vd_base_rate[i][j]
#     ln_y[k] = vd_rate[i][j]
#     vd_base_rate[i][j].redraw() 
# }
# mean(y)
# sqrt(var(y))
# sqrt(var(ln_y))
# md_matrix[i][j]
# sd_vd[j]
# xxxxx

# Return model
# assume matrix R_ij for returning from away-location i into home-location j
# M1: all-equal: all return rates equal
# M2: row-equal: all return rates from away-location i are equal
# M3: col-equal: all return rates into home-location j are equal
# M4: none-equal: all return rates differ

# log rates
# prior on log-rate
# exp(-3) = 0.04978707
# exp(0) = 1.0

# Come up with new parameters so return time is mean=2 weeks [1 day and 3 months??]
# https://ourworldindata.org/grapher/average-length-of-stay

# vr_base_dist = dnLognormal(ln(1/10),0.5)   # median return of 10 days, 95%HPD [4,38] days 

# none-equal
# vr_rate[i][j] means returning from location j to home location i 

for (i in 1:num_loc) {
    for (j in 1:num_loc) {
        vr_rate[i][j] <- abs(0)
        vr_base_rate[i][j] <- abs(0)
        if (i != j){
            vr_base_rate[i][j] ~  dnLognormal(mean = ln(mr_matrix[i][j])-0.5*sd_vr[i]^2,sd = sd_vr[i])
            vr_rate[i][j] := ln(vr_base_rate[i][j])
        }
    }
}



# build stationary frequency matrix, P, per individual
for (m in 1:num_loc) {
    # get the log-product of return rates per row
    sum_log_vr_rate[m] := sum(vr_rate[m])
    for (n in 1:num_loc) {
        if (m == n) {
            Pu[m][n] := exp(sum_log_vr_rate[m] - vr_rate[m][m])
            # print("Pu = ", Pu[m][m])
        } else {
            Pu[m][n] := exp(vd_rate[m][n] + sum_log_vr_rate[m] - vr_rate[m][m] - vr_rate[n][m])
            # print("Pu = ", Pu[m][m])
        }
    }
}
# normalized P with rows P_m = Pu_m / sum(Pu_m) and sum(P_m) == 1
for (m in 1:num_loc) {
    P[m] := Pu[m] / sum(Pu[m])
}

# ps_str = ""
# for (m in 1:num_loc) {
#     for (n in 1:num_loc) {
#         PS_0[m][n] := S_0[m] * P[m][n]
#         ps_str += "" + PS_0[m][n] + "\t"
#     }
#     ps_str += "\n"
# }

# print(ps_str)


# build visitor movement matrix, M
# needs no rate corrections
for (i in 1:num_states) {
    # from location, home and away
    ih = joint_loc[i][1]
    ia = joint_loc[i][2]
    for (j in 1:num_states) {
        # to location, home and away
        jh = joint_loc[j][1]
        ja = joint_loc[j][2]

        if (i == j) {
            # zero diagonal
            M[i][j] <- 0.0
        } else if (ih == jh && ih == ja) {
            # return event
            M[i][j] := exp(vr_rate[ih][ja])
        } else if (ih == jh && ih == ia && ih != ja) {
            # depart event
            M[i][j] := exp(vd_rate[ih][ja])
        } else {
            # no other events allowed
            M[i][j] <- 0.0
        }
    }
}

eta := fnFreeK(M, rescaled = FALSE)


## possible events
# anc     -> anc     + new
# (ih,ia) -> (ih,ia) + (ih,ia)  YES
# (jh,ia) -> (jh,ia) + (ih,ia)  YES
# (jh,ja) -> (jh,ja) + (ih,ja)  YES

# h: susceptible home, i: contagious home, j: infection location

clado_idx = 1
for (h in 1:num_loc) {
    for (i in 1:num_loc) {
        for (j in 1:num_loc) {
            s_old = joint_loc_inv[i][j] - 1
            s_new = joint_loc_inv[h][j] - 1
			lambda_P[h][j] := lambda[j] * P[h][j]
            if (s_old != s_new) {
                # divide by 2 for left-right
                clado_rates[clado_idx] := lambda_P[h][j] / 2.0
                clado_events[clado_idx++] = [ s_old, s_old, s_new ]
                clado_rates[clado_idx] := lambda_P[h][j] / 2.0
                clado_events[clado_idx++] = [ s_old, s_new, s_old ]
            } else {
                clado_rates[clado_idx] := lambda_P[h][j]
                clado_events[clado_idx++] = [ s_old, s_old, s_old ]
            }
        }
    }
}


sum_rate_0 = 0
for (i in 1:clado_events.size()) {
    if (clado_events[i][1] == 0 ||
        clado_events[i][1] == 5 ||
        clado_events[i][1] == 10 ||
        clado_events[i][1] == 15 ||
        clado_events[i][1] == 20) {
        sum_rate_0 += clado_rates[i]
    }
}


if (print_debug) {
    print("Compound state encoding")
    for (i in home_loc) {
        for (j in away_loc) {
            print("home = " + i + " away = " + j + " -> joint = " + joint_loc_inv[i][j])
        }
    }

    print("Visit return rates")
    if (vd_model == 1) print("M1: all-equal: all depart rates equal")
    if (vd_model == 2) print("M2: row-equal: all depart rates from home-location i are equal")
    if (vd_model == 3) print("M3: col-equal: all depart rates into away-location j are equal")
    if (vd_model == 4) print("M4: none-equal: all depart rates differ")
    for (i in 1:num_loc) {
    	print(vr_rate[i])
    }

    print("Visit depart rates")
    if (vr_model == 1) print("M1: all-equal: all return rates equal")
    if (vr_model == 2) print("M2: row-equal: all return rates from home-location i are equal")
    if (vr_model == 3) print("M3: col-equal: all return rates into away-location j are equal")
    if (vr_model == 4) print("M4: none-equal: all return rates differ")
    for (i in 1:num_loc) {
    	print(vd_rate[i])
    }

    
    print ("Cladogenetic rates")
    for (i in 1:clado_events.size()) { 
        print(i + ":  " + clado_events[i] + "    rate = " + clado_rates[i])
    }

    print("Anagenetic rates")
    for (i in 1:eta.size()) {
        print(eta[i])
    }

    print("num_taxa = ", num_taxa)
    print("age = ", age)
}

clado_map := fnCladogeneticSpeciationRateMatrix(clado_events, clado_rates, num_states)
omega := clado_map.getCladogeneticProbabilityMatrix()
sum_rates := clado_map.getSpeciationRateSumPerState()

# root state frequencies
for (i in 1:num_states) {
    h = joint_loc[i][1]
    j = joint_loc[i][2]
    root_freq_u[i] := abs(S_0[h] * P[h][j])
}
root_freq := simplex(root_freq_u)

# condition for diversification model
condition <- "survival"

# tensorphylo bug when using originAge
psi ~ dnGeneralizedLineageHeterogeneousBirthDeathProcess(
        originAge    = age,
        pi           = root_freq,
        lambda       = lambda,
        eta          = eta,
        mu           = gamma,
        omega        = omega,
        delta        = delta,
        rho          = rho,
        condition    = condition,
        taxa         = taxa,
        nStates      = num_states,
        zeroIndex    = TRUE,
        nProc        = 10
)

print("no clamp", psi.lnProbability())
psi.clamp(tree)
print("after clamp tree", psi.lnProbability())
psi.clampCharData(data)
print("after clamp data", psi.lnProbability())



## Define moves
moves = VectorMoves()

if (!fix_R0) {
	for (i in 1:num_loc) {
		moves.append(mvScale(R_0_param[i], weight = mv_weight, tune=true))
	}
}
if (!fix_delta) {
	for (i in 1:num_loc) {
		moves.append(mvScale(delta_prop[i], weight = mv_weight, tune=true))
	}
}

# gamma, recovery rate
if (update_recovery_rate) {
    moves.append(mvSlide(gamma_param, weight=mv_weight, tune=true))
}

# vr, visit-return rate
for (i in 1:num_loc) {
    for (j in 1:num_loc) {
        if (i!=j){
            moves.append(mvScale(vr_base_rate[i][j], weight=mv_weight, tune=true))
        }
    }
}

# vd, visit-depart rate
for (i in 1:num_loc) {
    for (j in 1:num_loc) {
        if(i != j){
            moves.append(mvScale(vd_base_rate[i][j], weight=mv_weight, tune=true))
        }
    }
}

if (false) {
    # MJL 240318: causes segfault??
    # delta, R0 joint move
    moves.append(mvUpDownSlide(weight=mv_weight, tune=true))
    deltaR0_joint_updown_idx = moves.size()
    moves[deltaR0_joint_updown_idx].addVariable(delta_param, true)
    moves[deltaR0_joint_updown_idx].addVariable(R_0_param, false)
}

## Define monitors
monitors = VectorMonitors()
monitors.append(mnScreen(printgen=print_gen))
monitors.append(mnModel(printgen=print_gen * thin, filename=out_fn + ".model.log"))
monitors.append(mnFile(R_0, delta,vr_rate, vd_rate, printgen=print_gen * thin, filename=out_fn + ".model.json", format="json"))
# this is for ancestral state reconstruction
monitors.append(mnJointConditionalAncestralState(tree, psi, filename = out_fn + ".ancStates", 
        type = "Standard", printgen = print_gen * thin, withStartStates = true)) 
# this is for stochastic character map
monitors.append(mnStochasticCharacterMap(glhbdsp=psi, printgen=print_gen * thin, filename= out_fn + ".stoch.txt", use_simmap_default=false) )
## Define model
my_model = model(psi)

# analysis
my_mcmc = mcmc(my_model, monitors, moves, moveschedule=move_schedule)
#if (f_burn > 0) {
#    my_mcmc.burnin(num_gen * f_burn, 100)
#}
my_mcmc.run(num_gen)

print("run time (min): " + (time("seconds") - start_time)/60)
q()


